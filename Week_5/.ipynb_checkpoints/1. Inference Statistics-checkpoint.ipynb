{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference Statistics\n",
    "\n",
    "## Descriptive Statistics\n",
    "\n",
    "The scientific method\n",
    "\n",
    "![title](Scientific_Method_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "As we have seen previously, many of the distributions we have seen (discrete and continuous) when we increase our sample size, sufficiently, the mean of all samples drawn from the population will be approximately equal to the mean of the population.\n",
    "\n",
    "These samples will follow an approximate normal distribution, with the variances approximatelly equal to the variance of the population divided by the sample's size.\n",
    "\n",
    "In many instances a sufficiently large sample is generalized to a size larger than 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Review an example that will allows to introduce our next topic Point Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lets generate some data that represent the whole population age distribution\n",
    "##install.packages(\"e1071\")\n",
    "library(e1071)\n",
    "set.seed(12)\n",
    "population_ages <- c(rexp(1000000,0.015)+18,   # Generate a population\n",
    "                     rpois(500000,20)+18,\n",
    "                     rpois(500000,32.5)+18,\n",
    "                     rpois(500000,45)+18)\n",
    "\n",
    "population_ages <- ifelse(population_ages<100, population_ages, population_ages%%100+18)\n",
    "\n",
    "true_mean <- mean(population_ages)\n",
    "true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(population_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "sample_ages <- sample(population_ages, size=1000)  # Take a sample of 1000 ages\n",
    "\n",
    "sample_mean <- mean(sample_ages)            # Make a point estimate of the mean\n",
    "\n",
    "sample_mean\n",
    "\n",
    "sample_mean-true_mean   # Check difference between estimate and population parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(population_ages, breaks=20)  # Create histogram of population\n",
    "\n",
    "skewness(population_ages)         # Check the skewness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sample_ages, breaks=20)   # Create histogram of the sample\n",
    "\n",
    "skewness(sample_ages)          # Check the skewness (point estimate of skewness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(12)\n",
    "point_estimates <- c()    # Create an empty vector to hold results\n",
    "\n",
    "num_samples <- 200        # Initialize number of samples to take\n",
    "\n",
    "for (x in 1:num_samples){         # Draw 200 samples and make 200 point estimates\n",
    "  sample <- sample(population_ages, size=1000)\n",
    "  point_estimates <- c(point_estimates, mean(sample))\n",
    "}\n",
    "\n",
    "plot(density(point_estimates))  # Plot the sampling distribution\n",
    "skewness(point_estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(point_estimates)\n",
    "\n",
    "mean(point_estimates)-true_mean    # Difference between true mean and sample means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score\n",
    "\n",
    "STANDARDIZATION â€“ an expression of a raw score in terms of standard deviation units (useful to compare results from data that uses different scales of measurement)\n",
    "\n",
    "THE STANDARD NORMAL CURVE:  N(0,1) is defined as\n",
    "\n",
    "$$ f(x | \\mu, \\sigma^2) = \\frac {1} { \\sqrt {2\\pi}} e^ -{\\frac {({x })^2} {2}} $$\n",
    "\n",
    "with $\\mu = 0$ and $\\sigma = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation used is Z ~ N(0,1)\n",
    "\n",
    "where $Z = \\frac{X-\\bar{x}}{s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Example: \n",
    "\n",
    "We collected data from a sample, and we found that the age distribution had a mean of 49.3 and a variance of  260 (both sides of the curve), standard deviation is sqrt(260) = 12.1245. What is the z-score (standard score of an individual of age 53?\n",
    "\n",
    "\n",
    "X ~ N(49.3, 260)\n",
    "\n",
    "Age of 53 = z $\\frac {53 - 49.3}{16.1245}$ = 0.2294\n",
    "\n",
    "An individual of 53 years of age is approximatelly 0.23 standard deviations above the mean\n",
    "\n",
    "Recall that the area under the curve up to the Z value represents the probability of obtaining that Z value or less, thus for a z = 0.2294, what is the exact area under the curve? looking at the curves below we can say that the probability is at least less than 0.6827, but to get to the exact value we need to look at the z table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](z_curve.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This z table represents the CDF cumulative distribution for the z scores, to calculate the area under the curve to the left of a particular value, we search the table on the right (Table of Standard Normal Probabilities for Positive Z-scores), for 0.2294 then we have an area of 0.5871. which means that about 59% of the ages are below this subject's. \n",
    "\n",
    "If we want to know the area between the mean and the z-score, simply subtract 0.5 to to the total area from the table. In this case\n",
    "0.58 - 0.50 = 0.08 (which is the deviation from the mean).\n",
    "\n",
    "If we want to know the area right from the z-score we substract 1 to the area obtained from the table.\n",
    "1- 0.58 = 0.42 (42% of ages are above this subjet's age)\n",
    "\n",
    "#NOTE - or simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnorm(53,49.3,16.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](z-table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "A point estimate can give you a rough idea of a population parameter like the mean, but estimates are prone to error and taking multiple samples to get improved estimates may not be feasible. \n",
    "\n",
    "A confidence interval is a range of values above and below a point estimate that captures the true population parameter at some predetermined confidence level. For example, if you want to have a 95% chance of capturing the true population parameter with a point estimate and a corresponding confidence interval, you'd set your confidence level to 95%. Higher confidence levels result in a wider confidence intervals.\n",
    "\n",
    "\n",
    "Calculate a confidence interval by taking a point estimate and then adding and subtracting a margin of error to create a range. Margin of error is based on your desired confidence level, the spread of the data and the size of your sample. The way you calculate the margin of error depends on whether you know the standard deviation of the population or not.\n",
    "\n",
    "\n",
    "If you know the standard deviation of the population, the margin of error is equal to:\n",
    "\n",
    "$$ z * \\frac {\\sigma}{\\sqrt{\\bar{n}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"mosaic\")\n",
    "library(mosaic)\n",
    "\n",
    "trellis.par.set(theme=col.mosaic())\n",
    "options(digits=3)\n",
    "\n",
    "###\n",
    "mu = 500\n",
    "sigma = 100\n",
    "x = rnorm(500, mean=mu, sd=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##produces a complete set of stats from a vector\n",
    "favstats(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introducing a kernel density estimator\n",
    "plot(density(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Estimating confidence intervals\n",
    "\n",
    "meanconfint = function (x, sigma, level = 0.95, ...) {\n",
    "  se = sigma / sqrt(length(x))\n",
    "  mu = mean(x)\n",
    "  z = qnorm(1 - (1 - level)/2)\n",
    "  out = c(mu, mu - z * se, mu + z * se)\n",
    "  names(out) = c(\"mean\", \"lower\", \"upper\")\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "meanconfint(x, sigma = sigma)\n",
    "\n",
    "z_critical <- qnorm(0.975)\n",
    "z_critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###do function from the mosaic package, repear something many times\n",
    "randomx = do(50) * rnorm(500, mean=mu, sd=sigma)\n",
    "\n",
    "ci = data.frame(t(apply(randomx, 1, meanconfint, sigma=sigma)))\n",
    "head(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot confidence intervals -- sometimes the \n",
    "### simulation it doesn't cover the actual mean\n",
    "xyplot(1:nrow(ci) ~ mean, data=ci, xlim=range(ci), xlab=\"SAT score\", ylab=\"Index\")\n",
    "ladd(panel.abline(v=500, col=\"lightgray\", lty=2))\n",
    "ladd(with(ci, panel.arrows(x0 = lower, y0=1:nrow(ci), y1=1:nrow(ci), cex=0.5,\n",
    "                             x1=upper, code=3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The package mosaic has a nice bootstrap function called resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = c(190.5, 109, 95.5, 137)\n",
    "resample(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap = do(10) * mean(resample(time))\n",
    "head(bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityplot(~mean, data=bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Once we have collected our data based on our initial hypothesis, is time to start exploring relationships across variables and they type of data that we have gathered.\n",
    "\n",
    "We saw that point estimators allows us to have a general idea of the type of data and tha ranges where the data operates.\n",
    "\n",
    "Next week, we will review multiple methods that allows us to detect possible error in the data and explore types of estimators that will help us with our analysis.\n",
    "\n",
    "The central idea of hypothesis testing is to mathematically test whether our expectations are approximatelly close to the real population parameters. \n",
    "\n",
    "The classical approach is to generate intrinsic hypothesis which will allow to compartamentalize the decision regarding the validity of the approach.\n",
    "\n",
    "### $H_o$ *null hypothesis* It is normally the default value - usually is the condition that is false\n",
    "\n",
    "### $H_1$ *Alternative hypothese* It is normally the hypothesis we want to test (the one that is true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We want to be able to determine with some percentage of confidence (normally it is 95) if we can reject the null hypothesis, in favor of the Alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Is the coin biased?? Hypothesis testing\n",
    "library(mosaic)\n",
    "n_tosses = 1000\n",
    "\n",
    "lower_bound = qbinom(0.025, n_tosses, 0.5)\n",
    "upper_bound = qbinom(0.975, n_tosses, 0.5)\n",
    "\n",
    "\n",
    "lower_bound\n",
    "upper_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_flip = function(){\n",
    "  ifelse(runif(1)>0.51,1,0)\n",
    "}\n",
    "\n",
    "coin_flip_biased = function(){\n",
    "  rbinom(1,1,0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_head_count = sum(do(n_tosses) * coin_flip())\n",
    "#observed_head_count = sum(do(n_tosses) * coin_flip_biased())\n",
    "\n",
    "if (observed_head_count >= lower_bound & observed_head_count <= upper_bound){\n",
    "  print(\"Failed to reject the null!\")\n",
    "}else{\n",
    "  print(\"Null rejected!\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(observed_head_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formally, hypothesis testing can be expressed: if X is a random variable and R is the range of X. $R_{reject} \\subset $ R is the rejection region. If $X \\in R_{reject}$ then the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rnorm(1000,0,1)\n",
    "y = rnorm(1000,2,1)\n",
    "\n",
    "dx = density(x)\n",
    "dy = density(y)\n",
    "\n",
    "plot(dx, xlim = c(-8,12))\n",
    "lines(dy, col = \"forestgreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rnorm(1000,0,0.5)\n",
    "y = rnorm(1000,0,2)\n",
    "\n",
    "dx = density(x)\n",
    "dy = density(y)\n",
    "\n",
    "plot(dx, xlim = c(-8,12))\n",
    "lines(dy, col = \"forestgreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
