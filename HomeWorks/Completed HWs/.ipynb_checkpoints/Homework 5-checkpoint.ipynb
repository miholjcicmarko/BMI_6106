{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "\n",
    "From the diabates dataset seen on previous classes, fit a logistic regression model using the binary variable Outcome as the outcome variable and all of the other continuous variables as predictors.\n",
    "\n",
    "The idea is to find the model that best fit the data, and produce a list of optimal coefficients that will allow to predict outcomes from new data. For this you can use some or all of the resources seen in class, and other resources that can increase the resolution and accuracy of the model.\n",
    "\n",
    "lm functions in R (or Python sklearn.linear_model) <br>\n",
    "Cross-validation<br>\n",
    "k-fold cross-validation<br>\n",
    "Maximum likelihood estimation of coefficients <br>\n",
    "Gradient Descent optimization<br>\n",
    "Regularization<br>\n",
    "\n",
    "Other methods for optimization such: forward-backward model selection\n",
    "\n",
    "##### Examples..\n",
    "\n",
    "[https://eight2late.wordpress.com/2017/07/11/a-gentle-introduction-to-logistic-regression-and-lasso-regularisation-using-r/](https://eight2late.wordpress.com/2017/07/11/a-gentle-introduction-to-logistic-regression-and-lasso-regularisation-using-r/)\n",
    "\n",
    "[https://www.kaggle.com/c/titanic/discussion/13582#73042](https://www.kaggle.com/c/titanic/discussion/13582#73042)\n",
    "\n",
    "[https://www.r-bloggers.com/logistic-regression-regularized-with-optimization/](https://www.r-bloggers.com/logistic-regression-regularized-with-optimization/)\n",
    "\n",
    "[https://www.r-bloggers.com/predicting-creditability-using-logistic-regression-in-r-cross-validating-the-classifier-part-2-2/](https://www.r-bloggers.com/predicting-creditability-using-logistic-regression-in-r-cross-validating-the-classifier-part-2-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(mosaic)\n",
    "library(swirl)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- read.csv('/Users/markomiholjcic/Documents/BMI_6106/HomeWorks/Homework_5/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- na.omit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Pregnancies</dt><dd>'integer'</dd><dt>Glucose</dt><dd>'integer'</dd><dt>BloodPressure</dt><dd>'integer'</dd><dt>SkinThickness</dt><dd>'integer'</dd><dt>Insulin</dt><dd>'integer'</dd><dt>BMI</dt><dd>'numeric'</dd><dt>DiabetesPedigreeFunction</dt><dd>'numeric'</dd><dt>Age</dt><dd>'integer'</dd><dt>Outcome</dt><dd>'integer'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Pregnancies] 'integer'\n",
       "\\item[Glucose] 'integer'\n",
       "\\item[BloodPressure] 'integer'\n",
       "\\item[SkinThickness] 'integer'\n",
       "\\item[Insulin] 'integer'\n",
       "\\item[BMI] 'numeric'\n",
       "\\item[DiabetesPedigreeFunction] 'numeric'\n",
       "\\item[Age] 'integer'\n",
       "\\item[Outcome] 'integer'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Pregnancies\n",
       ":   'integer'Glucose\n",
       ":   'integer'BloodPressure\n",
       ":   'integer'SkinThickness\n",
       ":   'integer'Insulin\n",
       ":   'integer'BMI\n",
       ":   'numeric'DiabetesPedigreeFunction\n",
       ":   'numeric'Age\n",
       ":   'integer'Outcome\n",
       ":   'integer'\n",
       "\n"
      ],
      "text/plain": [
       "             Pregnancies                  Glucose            BloodPressure \n",
       "               \"integer\"                \"integer\"                \"integer\" \n",
       "           SkinThickness                  Insulin                      BMI \n",
       "               \"integer\"                \"integer\"                \"numeric\" \n",
       "DiabetesPedigreeFunction                      Age                  Outcome \n",
       "               \"numeric\"                \"integer\"                \"integer\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sapply(df, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 <- glm(Outcome ~ Glucose + BloodPressure + SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+\n",
    "            Age, family = \"binomial\", data = df) \n",
    "summary(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(randomForest)\n",
    "library(varImp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df$Outcome = as.factor(df$Outcome)\n",
    "set.seed(998)\n",
    "indxTrain <- createDataPartition(y = df$Outcome,p = 0.75,list = FALSE)\n",
    "training <- df[indxTrain,] \n",
    "testing <- df[-indxTrain,] \n",
    "\n",
    "z = testing$Outcome\n",
    "z = as.factor(z)\n",
    "\n",
    "train.control <- trainControl(method = \"cv\", number = 10)\n",
    "# Train the model\n",
    "model <- train(Outcome ~ Glucose + BloodPressure + SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+\n",
    "            Age, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "# Summarize the results\n",
    "print(model)\n",
    "\n",
    "Predict <- predict(model,newdata = testing)\n",
    "\n",
    "confusionMatrix(Predict, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 fold Cross Validation was performed on the model. The Accuracy of the model is 79%. The model is better than the no information rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X <- caret::varImp(model)\n",
    "plot(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SkinThickness variable is not important to the model. Therefore, this variable can be removed in an attempt to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df$Outcome = as.factor(df$Outcome)\n",
    "set.seed(998)\n",
    "indxTrain <- createDataPartition(y = df$Outcome,p = 0.75,list = FALSE)\n",
    "training <- df[indxTrain,] \n",
    "testing <- df[-indxTrain,] \n",
    "\n",
    "z = testing$Outcome\n",
    "z = as.factor(z)\n",
    "\n",
    "train.control <- trainControl(method = \"cv\", number = 10)\n",
    "# Train the model\n",
    "model <- train(Outcome ~ Glucose + BloodPressure + Insulin+BMI+DiabetesPedigreeFunction+\n",
    "            Age, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "# Summarize the results\n",
    "print(model)\n",
    "\n",
    "Predict <- predict(model,newdata = testing)\n",
    "\n",
    "confusionMatrix(Predict, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did not improve signinificantly with the removal of the SkinThickness variable. The accuracy and the 95% confidence interval have remained the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X <- caret::varImp(model)\n",
    "plot(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blood Pressure, DiabetesPedigreeFunction, and Insulin have greatly decreased in importance after the removal of the SkinThickness variable. These two variables will be removed in an attempt to make the model more accuracte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df$Outcome = as.factor(df$Outcome)\n",
    "set.seed(998)\n",
    "indxTrain <- createDataPartition(y = df$Outcome,p = 0.75,list = FALSE)\n",
    "training <- df[indxTrain,] \n",
    "testing <- df[-indxTrain,] \n",
    "\n",
    "z = testing$Outcome\n",
    "z = as.factor(z)\n",
    "\n",
    "train.control <- trainControl(method = \"cv\", number = 10)\n",
    "# Train the model\n",
    "model <- train(Outcome ~ Glucose+BMI+\n",
    "            Age, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "# Summarize the results\n",
    "print(model)\n",
    "\n",
    "Predict <- predict(model,newdata = testing)\n",
    "\n",
    "confusionMatrix(Predict, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy has barely increased with the removal of Blood Pressure, DiabetesPedigreeFunction  and Insulin. The accuracy percentage is now at 79.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X <- caret::varImp(model)\n",
    "plot(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each removal, each variable continues to decrease in importance. There is one exception to this trend which is the glucose variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df$Outcome = as.factor(df$Outcome)\n",
    "set.seed(998)\n",
    "indxTrain <- createDataPartition(y = df$Outcome,p = 0.75,list = FALSE)\n",
    "training <- df[indxTrain,] \n",
    "testing <- df[-indxTrain,] \n",
    "\n",
    "z = testing$Outcome\n",
    "z = as.factor(z)\n",
    "\n",
    "train.control <- trainControl(method = \"cv\", number = 10)\n",
    "# Train the model\n",
    "model <- train(Outcome ~ Glucose, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "# Summarize the results\n",
    "print(model)\n",
    "\n",
    "Predict <- predict(model,newdata = testing)\n",
    "\n",
    "confusionMatrix(Predict, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When glucose is the only variable, the accuracy of the model falls. Therefore, the model including Glucose, BMI, and Age is the best model so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave one out cross validation was performed on all of the tests as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(998) \n",
    "train.control <- trainControl(method = \"LOOCV\")\n",
    "\n",
    "model <- train(Outcome ~ Glucose + BloodPressure + SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+\n",
    "            Age, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(998) \n",
    "train.control <- trainControl(method = \"LOOCV\")\n",
    "\n",
    "model <- train(Outcome ~ Glucose + BloodPressure + Insulin+BMI+DiabetesPedigreeFunction+\n",
    "            Age, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(998) \n",
    "train.control <- trainControl(method = \"LOOCV\")\n",
    "# Train the model\n",
    "model <- train(Outcome ~ Glucose+BMI+Age, data = training, \n",
    "                method = \"glm\",\n",
    "               trControl = train.control)\n",
    "# Summarize the results\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(998) \n",
    "train.control <- trainControl(method = \"LOOCV\")\n",
    "\n",
    "model <- train(Outcome ~ Glucose, data = training, method = \"glm\",\n",
    "               trControl = train.control)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Leave One Out Cross Validation was performed on all of the models. The three predictor model of BMI, Age, and Glucose was slightly less accurate than the six predictor model. The difference was 0.0007 between the two models. Regardless, the three predictor model of BMI, Age, and Glucose is a top performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- read.csv('/Users/markomiholjcic/Documents/BMI_6106/HomeWorks/Homework_5/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2000</li><li>9</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2000\n",
       "\\item 9\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2000\n",
       "2. 9\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2000    9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- na.omit(df)\n",
    "dim(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Pregnancies</dt><dd>'integer'</dd><dt>Glucose</dt><dd>'integer'</dd><dt>BloodPressure</dt><dd>'integer'</dd><dt>SkinThickness</dt><dd>'integer'</dd><dt>Insulin</dt><dd>'integer'</dd><dt>BMI</dt><dd>'numeric'</dd><dt>DiabetesPedigreeFunction</dt><dd>'numeric'</dd><dt>Age</dt><dd>'integer'</dd><dt>Outcome</dt><dd>'integer'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Pregnancies] 'integer'\n",
       "\\item[Glucose] 'integer'\n",
       "\\item[BloodPressure] 'integer'\n",
       "\\item[SkinThickness] 'integer'\n",
       "\\item[Insulin] 'integer'\n",
       "\\item[BMI] 'numeric'\n",
       "\\item[DiabetesPedigreeFunction] 'numeric'\n",
       "\\item[Age] 'integer'\n",
       "\\item[Outcome] 'integer'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Pregnancies\n",
       ":   'integer'Glucose\n",
       ":   'integer'BloodPressure\n",
       ":   'integer'SkinThickness\n",
       ":   'integer'Insulin\n",
       ":   'integer'BMI\n",
       ":   'numeric'DiabetesPedigreeFunction\n",
       ":   'numeric'Age\n",
       ":   'integer'Outcome\n",
       ":   'integer'\n",
       "\n"
      ],
      "text/plain": [
       "             Pregnancies                  Glucose            BloodPressure \n",
       "               \"integer\"                \"integer\"                \"integer\" \n",
       "           SkinThickness                  Insulin                      BMI \n",
       "               \"integer\"                \"integer\"                \"numeric\" \n",
       "DiabetesPedigreeFunction                      Age                  Outcome \n",
       "               \"numeric\"                \"integer\"                \"integer\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sapply(df, class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)  # setting seed to reproduce results of random sampling\n",
    "trainingRowIndex <- sample(1:nrow(df), 0.75*nrow(df))  # row indices for training data\n",
    "\n",
    "xvars.train <- as.matrix(df[trainingRowIndex,2:8])\n",
    "xvars.test <- as.matrix(df[-trainingRowIndex,2:8])\n",
    "\n",
    "y.train <- as.matrix(df[trainingRowIndex, 9])\n",
    "y.test <- as.matrix(df[-trainingRowIndex, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded glmnet 3.0-2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(glmnet)\n",
    "fitlasso <- glmnet(xvars.train, y.train, family=\"binomial\", alpha=1)\n",
    "fitridge <- glmnet(xvars.train, y.train, family=\"binomial\", alpha=0)\n",
    "fitelnet <- glmnet(xvars.train, y.train, family=\"binomial\", alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 0:10) {\n",
    "    assign(paste(\"fit\", i, sep=\"\"), cv.glmnet(xvars.train, y.train, type.measure=\"mse\", \n",
    "                                              alpha=i/10,family=\"binomial\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 500 × 1 of type int</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>⋮</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 500 × 1 of type int\n",
       "\\begin{tabular}{l}\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t ⋮\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 500 × 1 of type int\n",
       "\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| ⋮ |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 1 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]\n",
       " [1,] 0   \n",
       " [2,] 0   \n",
       " [3,] 0   \n",
       " [4,] 0   \n",
       " [5,] 0   \n",
       " [6,] 0   \n",
       " [7,] 1   \n",
       " [8,] 0   \n",
       " [9,] 1   \n",
       "[10,] 1   \n",
       "[11,] 0   \n",
       "[12,] 0   \n",
       "[13,] 1   \n",
       "[14,] 1   \n",
       "[15,] 0   \n",
       "[16,] 1   \n",
       "[17,] 1   \n",
       "[18,] 0   \n",
       "[19,] 0   \n",
       "[20,] 1   \n",
       "[21,] 0   \n",
       "[22,] 0   \n",
       "[23,] 0   \n",
       "[24,] 0   \n",
       "[25,] 1   \n",
       "[26,] 0   \n",
       "[27,] 0   \n",
       "[28,] 0   \n",
       "[29,] 0   \n",
       "[30,] 0   \n",
       "[31,] ⋮   \n",
       "[32,] 0   \n",
       "[33,] 0   \n",
       "[34,] 1   \n",
       "[35,] 0   \n",
       "[36,] 0   \n",
       "[37,] 0   \n",
       "[38,] 0   \n",
       "[39,] 0   \n",
       "[40,] 0   \n",
       "[41,] 0   \n",
       "[42,] 1   \n",
       "[43,] 0   \n",
       "[44,] 0   \n",
       "[45,] 1   \n",
       "[46,] 0   \n",
       "[47,] 1   \n",
       "[48,] 0   \n",
       "[49,] 1   \n",
       "[50,] 1   \n",
       "[51,] 0   \n",
       "[52,] 0   \n",
       "[53,] 0   \n",
       "[54,] 0   \n",
       "[55,] 1   \n",
       "[56,] 0   \n",
       "[57,] 1   \n",
       "[58,] 0   \n",
       "[59,] 1   \n",
       "[60,] 0   \n",
       "[61,] 1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AIC for Rigid:  -405.9876 \n",
      "[1] \"Lambda from AIC Ridge =  0.021160879728219\"\n",
      "Best BIC for Rigid:  -368.8702 \n",
      "[1] \"Lambda from BIC Ridge =  0.021160879728219\"\n",
      "Best AIC for Lasso:  -412.3716 \n",
      "[1] \"Lambda from AIC Lasso =  0.00425171377032666\"\n",
      "Best BIC for Lasso:  -380.5486 \n",
      "[1] \"Lambda from BIC Lasso=  0.00425171377032666\"\n",
      "Best AIC for Elastic Net:  -412.21 \n",
      "[1] \"Lambda AIC enet = 0.00132285793895594\"\n",
      "Best BIC for Elastic Net:  -379.1706 \n",
      "[1] \"Lambda BIC enet=  0.00850342754065331\"\n",
      "[1] \"mse Ridge AIC =  2.26368066043425\"\n",
      "[1] \"mse Ridge BIC =  2.26368066043425\"\n",
      "[1] \"mse Lasso AIC =  2.52382794545364\"\n",
      "[1] \"mse Lasso BIC =  2.52382794545364\"\n",
      "[1] \"mse elnet AIC =  2.64960216082435\"\n",
      "[1] \"mse elnet BIC =  2.43185319611129\"\n"
     ]
    }
   ],
   "source": [
    "##Find best AIC/BIC for each model\n",
    "##Ridge\n",
    "tLL <- fitridge$nulldev - deviance(fitridge) ##Likelihood of the model\n",
    "k <- fitridge$df ##Number of parameters\n",
    "n <- fitridge$nobs ##Sample Size\n",
    "\n",
    "##AIC\n",
    "\n",
    "AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc)\n",
    "cat(\"Best AIC for Rigid: \", m, \"\\n\")\n",
    "best_AIC = match(c(min(AICc)),AICc)\n",
    "print(paste(\"Lambda from AIC Ridge = \",fitridge$lambda[best_AIC]))\n",
    "\n",
    "##BIC\n",
    "BIC<-log(n)*k - tLL \n",
    "m = min(BIC)\n",
    "cat(\"Best BIC for Rigid: \", m, \"\\n\")\n",
    "best_BIC = match(c(min(BIC)),BIC)\n",
    "print(paste(\"Lambda from BIC Ridge = \",fitridge$lambda[best_BIC]))\n",
    "\n",
    "##Lasso\n",
    "##AIC\n",
    "tLL <- fitlasso$nulldev - deviance(fitlasso)\n",
    "k <- fitlasso$df\n",
    "n <- fitlasso$nobs\n",
    "AICc_lasso <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc_lasso)##Best AIC\n",
    "cat(\"Best AIC for Lasso: \", m, \"\\n\")\n",
    "best_AIC_lasso = match(c(min(AICc_lasso)),AICc_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from AIC Lasso = \",fitlasso$lambda[best_AIC_lasso]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_lasso<-log(n)*k - tLL \n",
    "m = min(BIC_lasso)##Best BIC\n",
    "cat(\"Best BIC for Lasso: \", m, \"\\n\")\n",
    "best_BIC_lasso = match(c(min(BIC_lasso)),BIC_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from BIC Lasso= \",fitlasso$lambda[best_BIC_lasso]))\n",
    "\n",
    "##Elastic Net\n",
    "##AIC\n",
    "tLL <- fitelnet$nulldev - deviance(fitelnet)\n",
    "k <- fitelnet$df\n",
    "n <- fitelnet$nobs\n",
    "AICc_elnet <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m= min(AICc_elnet)##Best AIC\n",
    "cat(\"Best AIC for Elastic Net: \", m, \"\\n\")\n",
    "best_AIC_elnet = match(c(min(AICc_elnet)),AICc_elnet)##Which index is this?\n",
    "print(paste(\"Lambda AIC enet =\",fitelnet$lambda[best_AIC_elnet]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_elnet<-log(n)*k - tLL \n",
    "m= min(BIC_elnet)##Best BIC\n",
    "cat(\"Best BIC for Elastic Net: \", m, \"\\n\")\n",
    "best_BIC_elnet = match(c(min(BIC_elnet)),BIC_elnet)##Which index is this?\n",
    "print(paste(\"Lambda BIC enet= \",fitelnet$lambda[best_BIC_elnet]))\n",
    "\n",
    "#Ridge AIC/BIC\n",
    "yRidgeAIC <- predict(fit0, s=fitridge$lambda[best_AIC], newx=xvars.test)\n",
    "mseRidgeAIC <- mean((y.test - yRidgeAIC)^2)\n",
    "print(paste(\"mse Ridge AIC = \", mseRidgeAIC))\n",
    "yRidgeBIC <- predict(fit0, s=fitridge$lambda[best_BIC], newx=xvars.test)\n",
    "mseRidgeBIC <- mean((y.test - yRidgeBIC)^2)\n",
    "print(paste(\"mse Ridge BIC = \", mseRidgeBIC))\n",
    "\n",
    "#Lasso AIC/BIC\n",
    "yLassoAIC <- predict(fit10, s=fitlasso$lambda[best_AIC_lasso], newx=xvars.test)\n",
    "mseLassoAIC <- mean((y.test - yLassoAIC)^2)\n",
    "print(paste(\"mse Lasso AIC = \", mseLassoAIC)) \n",
    "yLassoBIC <- predict(fit10, s=fitlasso$lambda[best_BIC_lasso], newx=xvars.test)\n",
    "mseLassoBIC <- mean((y.test - yLassoBIC)^2)\n",
    "print(paste(\"mse Lasso BIC = \", mseLassoBIC)) \n",
    "\n",
    "#Elastic Net AIC/BIC\n",
    "yelnetAIC <- predict(fit5, s=fitelnet$lambda[best_AIC_elnet], newx=xvars.test)\n",
    "mseelnetAIC <- mean((y.test - yelnetAIC)^2)\n",
    "print(paste(\"mse elnet AIC = \",mseelnetAIC))\n",
    "\n",
    "yelnetBIC <- predict(fit5, s=fitelnet$lambda[best_BIC_elnet], newx=xvars.test)\n",
    "mseelnetBIC <- mean((y.test - yelnetBIC)^2)\n",
    "print(paste(\"mse elnet BIC = \",mseelnetBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge has the smallest mse. Lasso and Elastic Net are not far behind. Lasso fit has the smallest AIC and BIC value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(fitlasso,s=fitlasso$lambda[best_AIC_lasso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)  # setting seed to reproduce results of random sampling\n",
    "trainingRowIndex <- sample(1:nrow(df), 0.75*nrow(df))  # row indices for training data\n",
    "\n",
    "xvars.train <- as.matrix(df[trainingRowIndex,2:8])\n",
    "xvars.test <- as.matrix(df[-trainingRowIndex,2:8])\n",
    "\n",
    "y.train <- as.matrix(df[trainingRowIndex, 9])\n",
    "y.test <- as.matrix(df[-trainingRowIndex, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLassoAIC <- predict(fit10, s=fitlasso$lambda[best_AIC_lasso], newx=xvars.test, type = \"response\")\n",
    "\n",
    "lasso_predict <- rep(0,nrow(xvars.test))\n",
    "lasso_predict[yLassoAIC>=0.5] <- 1\n",
    "table(pred=lasso_predict,true=y.test)\n",
    "acc <- mean(lasso_predict==y.test)\n",
    "print(paste(\"Accuracy of Lasso AIC = \",acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso regulariation model did not produce a higher accuracy than the multivariable regression model involving Glucose, BMI, and Age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- array(numeric(),c(1,9))\n",
    "for (i in 0:10) {\n",
    "    \n",
    "    set.seed(100+i)  # setting seed to reproduce results of random sampling\n",
    "    trainingRowIndex <- sample(1:nrow(df), 0.75*nrow(df)) \n",
    "    \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[trainingRowIndex,2:8])\n",
    "    xvars.test <- as.matrix(df[-trainingRowIndex,2:8])\n",
    "\n",
    "    y.train <- as.matrix(df[trainingRowIndex, 9])\n",
    "    y.test <- as.matrix(df[-trainingRowIndex, 9])\n",
    "\n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 1, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 1, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"10-fold Cross Validation for Lasso Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-fold Cross Validation of the Lasso Regression produced worse results than the 10-fold Cross Validation for the other multivariable regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- NULL\n",
    "for(i in 1:nrow(df))\n",
    "{   \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[-i,2:8])\n",
    "    xvars.test <- as.matrix(df[i,2:8])\n",
    "    \n",
    "    y.train <- as.matrix(df[-i, 9])\n",
    "    y.test <- as.matrix(df[i, 9])\n",
    "    \n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 1, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 1, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"Leave One Out Cross Validation for Lasso Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy is lower for the Leave One Out Cross Validation in comparison to the 10 Fold Cross Validation for Lasso Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- array(numeric(),c(1,9))\n",
    "for (i in 0:10) {\n",
    "    \n",
    "    set.seed(100+i)  # setting seed to reproduce results of random sampling\n",
    "    trainingRowIndex <- sample(1:nrow(df), 0.75*nrow(df)) \n",
    "    \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[trainingRowIndex,2:8])\n",
    "    xvars.test <- as.matrix(df[-trainingRowIndex,2:8])\n",
    "\n",
    "    y.train <- as.matrix(df[trainingRowIndex, 9])\n",
    "    y.test <- as.matrix(df[-trainingRowIndex, 9])\n",
    "\n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 0, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 0, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"10-fold Cross Validation for Rigid Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rigid Regression had a higher accuracy than Lasso Regression for the 10 fold Cross Validation. Rigid Regression is less accurate than the three multivariable model of BMI, Age and Glucose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- NULL\n",
    "for(i in 1:nrow(df))\n",
    "{   \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[-i,2:8])\n",
    "    xvars.test <- as.matrix(df[i,2:8])\n",
    "    \n",
    "    y.train <- as.matrix(df[-i, 9])\n",
    "    y.test <- as.matrix(df[i, 9])\n",
    "    \n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 0, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 0, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"Leave One Out Cross Validation for Rigid Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy is slightly better for the Leave One Out Cross Validation in comparison to the 10-fold Cross Validation for Rigid Regression. Rigid Regression is less accurate than the three multivariable model of BMI, Age and Glucose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- array(numeric(),c(1,9))\n",
    "for (i in 0:10) {\n",
    "    \n",
    "    set.seed(100+i)  # setting seed to reproduce results of random sampling\n",
    "    trainingRowIndex <- sample(1:nrow(df), 0.75*nrow(df)) \n",
    "    \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[trainingRowIndex,2:8])\n",
    "    xvars.test <- as.matrix(df[-trainingRowIndex,2:8])\n",
    "\n",
    "    y.train <- as.matrix(df[trainingRowIndex, 9])\n",
    "    y.test <- as.matrix(df[-trainingRowIndex, 9])\n",
    "\n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 0.5, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 0.5, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"10-fold Cross Validation for Elastic Net Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net Regression had a higher accuracy than Lasso Regression for the 10 fold Cross Validation. However, it had a lower accuracy than Rigid Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc <- NULL\n",
    "for(i in 1:nrow(df))\n",
    "{   \n",
    "    lambda_seq <- 10^seq(1, -1, by = -.01)\n",
    "    \n",
    "    xvars.train <- as.matrix(df[-i,2:8])\n",
    "    xvars.test <- as.matrix(df[i,2:8])\n",
    "    \n",
    "    y.train <- as.matrix(df[-i, 9])\n",
    "    y.test <- as.matrix(df[i, 9])\n",
    "    \n",
    "    model <- cv.glmnet(xvars.train, y.train, \n",
    "            alpha = 0.5, lambda = lambda_seq)\n",
    "\n",
    "    # finding the best lamda\n",
    "    min_lamb <- model$lambda.min\n",
    "    \n",
    "    lasso <- glmnet(xvars.train, y.train, alpha = 0.5, lambda = min_lamb)\n",
    "    pred <- predict(lasso, s = min_lamb, newx = xvars.test, type = \"response\")\n",
    "\n",
    "    lasso_predict <- rep(0,nrow(xvars.test))\n",
    "    lasso_predict[pred>=0.5] <- 1\n",
    "    \n",
    "    acc[i] <- mean(lasso_predict==y.test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- sum(acc)/length(acc)\n",
    "cat(\"Leave One Out Cross Validation for Elastic Net Regression: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy is slightly higher for the Leave One Out Cross Validation for Elastic Net Regression. The accuracy is still lower than the multivariable models created above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the model that produced the highest accuracy. It had the best accuracy for the 10-fold cross validation and it was a close second for the Leave One Out Cross Validation. The coefficients for the model are displayed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 <- glm(Outcome ~ Glucose +BMI+\n",
    "            Age, family = \"binomial\", data = df) \n",
    "summary(model_2)\n",
    "cat(\"Coefficients: \")\n",
    "coef(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regularization.\n",
    "\n",
    "Following the example given in class for the regularization procedures evaluate on each of the above simulations which is the most appropiate model (Ridge,Lasso,Elastic Net) using the appropiate variance measurements, produce the plots and write a small paragraph that explains the results. \n",
    "\n",
    "a.simulate new data, where the signal is strong but there is also lots of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)  # Package needed to generate correlated precictors\n",
    "library(glmnet)  # Package to fit ridge/lasso/elastic net models\n",
    "# Generate data\n",
    "set.seed(19874)\n",
    "n <- 1000    # Number of observations\n",
    "p <- 5000     # Number of predictors included in model\n",
    "real_p <- 1500  # Number of true predictors\n",
    "x <- matrix(rnorm(n*p), nrow=n, ncol=p)\n",
    "y <- apply(x[,1:real_p], 1, sum) + rnorm(n)\n",
    "\n",
    "train_rows <- sample(1:n, .66*n)\n",
    "x.train <- x[train_rows, ]\n",
    "x.test <- x[-train_rows, ]\n",
    "\n",
    "y.train <- y[train_rows]\n",
    "y.test <- y[-train_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitlasso <- glmnet(x.train, y.train, family=\"gaussian\", alpha=1)\n",
    "fitridge <- glmnet(x.train, y.train, family=\"gaussian\", alpha=0)\n",
    "fitelnet <- glmnet(x.train, y.train, family=\"gaussian\", alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 0:10) {\n",
    "    assign(paste(\"fit\", i, sep=\"\"), cv.glmnet(x.train, y.train, type.measure=\"mse\", \n",
    "                                              alpha=i/10,family=\"gaussian\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(3,2))\n",
    "\n",
    "plot(fitlasso, xvar=\"lambda\",label=TRUE)\n",
    "plot(fit10, main=\"LASSO\")\n",
    "\n",
    "plot(fitridge, xvar=\"lambda\")\n",
    "plot(fit0, main=\"Ridge\")\n",
    "\n",
    "plot(fitelnet, xvar=\"lambda\")\n",
    "plot(fit5, main=\"Elastic Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient values go to zero for the Lasso regression, when the log of lambda is above one. Coefficient values go to zero when the log of lambda is above 8 for the Rigid regression. Coefficient values go to zero when the log of lambda is above 2 for the Elastic Net regression. For each regression model, there are multiple coefficients at every level of importance (largely important to minimally important). The mean squared error plots of the Lasso, Ridge, and Elastic regressions display the large amount of noise in the dataset. There is a lot of variance in the results, no matter which lambda is chosen for all three regressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat0 <- predict(fit0, s=fit0$lambda.1se, newx=x.test)\n",
    "mse0 <- mean((y.test - yhat0)^2)\n",
    "yhat5 <- predict(fit5, s=fit5$lambda.1se, newx=x.test)\n",
    "mse5 <- mean((y.test - yhat5)^2)\n",
    "yhat10 <- predict(fit10, s=fit10$lambda.1se, newx=x.test)\n",
    "mse10 <- mean((y.test - yhat10)^2)\n",
    "\n",
    "cat(\"MSE for Ridge Regression\", mse0, \"\\n\")\n",
    "cat(\"MSE for Elastic Net Regression\", mse5, \"\\n\")\n",
    "cat(\"MSE for Lasso Regression\", mse10, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find best AIC/BIC for each model\n",
    "##Ridge\n",
    "tLL <- fitridge$nulldev - deviance(fitridge) ##Likelihood of the model\n",
    "k <- fitridge$df ##Number of parameters\n",
    "n <- fitridge$nobs ##Sample Size\n",
    "\n",
    "##AIC\n",
    "AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc)\n",
    "cat(\"Best AIC for Rigid: \", m, \"\\n\")\n",
    "best_AIC = match(c(min(AICc)),AICc)\n",
    "print(paste(\"Lambda from AIC Ridge = \",fitridge$lambda[best_AIC]))\n",
    "\n",
    "##BIC\n",
    "BIC<-log(n)*k - tLL \n",
    "m = min(BIC)\n",
    "cat(\"Best BIC for Rigid: \", m, \"\\n\")\n",
    "best_BIC = match(c(min(BIC)),BIC)\n",
    "print(paste(\"Lambda from BIC Ridge = \",fitridge$lambda[best_BIC]))\n",
    "\n",
    "##Lasso\n",
    "##AIC\n",
    "tLL <- fitlasso$nulldev - deviance(fitlasso)\n",
    "k <- fitlasso$df\n",
    "n <- fitlasso$nobs\n",
    "AICc_lasso <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc_lasso)##Best AIC\n",
    "cat(\"Best AIC for Lasso: \", m, \"\\n\")\n",
    "best_AIC_lasso = match(c(min(AICc_lasso)),AICc_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from AIC Lasso = \",fitlasso$lambda[best_AIC_lasso]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_lasso<-log(n)*k - tLL \n",
    "m = min(BIC_lasso)##Best BIC\n",
    "cat(\"Best BIC for Lasso: \", m, \"\\n\")\n",
    "best_BIC_lasso = match(c(min(BIC_lasso)),BIC_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from BIC Lasso= \",fitlasso$lambda[best_BIC_lasso]))\n",
    "\n",
    "##Elastic Net\n",
    "##AIC\n",
    "tLL <- fitelnet$nulldev - deviance(fitelnet)\n",
    "k <- fitelnet$df\n",
    "n <- fitelnet$nobs\n",
    "AICc_elnet <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m= min(AICc_elnet)##Best AIC\n",
    "cat(\"Best AIC for Elastic Net: \", m, \"\\n\")\n",
    "best_AIC_elnet = match(c(min(AICc_elnet)),AICc_elnet)##Which index is this?\n",
    "print(paste(\"Lambda AIC enet =\",fitelnet$lambda[best_AIC_elnet]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_elnet<-log(n)*k - tLL \n",
    "m= min(BIC_elnet)##Best BIC\n",
    "cat(\"Best BIC for Elastic Net: \", m, \"\\n\")\n",
    "best_BIC_elnet = match(c(min(BIC_elnet)),BIC_elnet)##Which index is this?\n",
    "print(paste(\"Lambda BIC enet= \",fitelnet$lambda[best_BIC_elnet]))\n",
    "\n",
    "#Ridge AIC/BIC\n",
    "yRidgeAIC <- predict(fit0, s=fitridge$lambda[best_AIC], newx=x.test)\n",
    "mseRidgeAIC <- mean((y.test - yRidgeAIC)^2)\n",
    "print(paste(\"mse Ridge AIC = \", mseRidgeAIC))\n",
    "yRidgeBIC <- predict(fit0, s=fitridge$lambda[best_BIC], newx=x.test)\n",
    "mseRidgeBIC <- mean((y.test - yRidgeBIC)^2)\n",
    "print(paste(\"mse Ridge BIC = \", mseRidgeBIC))\n",
    "\n",
    "#Lasso AIC/BIC\n",
    "yLassoAIC <- predict(fit10, s=fitlasso$lambda[best_AIC_lasso], newx=x.test)\n",
    "mseLassoAIC <- mean((y.test - yLassoAIC)^2)\n",
    "print(paste(\"mse Lasso AIC = \", mseLassoAIC)) \n",
    "yLassoBIC <- predict(fit10, s=fitlasso$lambda[best_BIC_lasso], newx=x.test)\n",
    "mseLassoBIC <- mean((y.test - yLassoBIC)^2)\n",
    "print(paste(\"mse Lasso BIC = \", mseLassoBIC)) \n",
    "\n",
    "#Elastic Net AIC/BIC\n",
    "yelnetAIC <- predict(fit5, s=fitelnet$lambda[best_AIC_elnet], newx=x.test)\n",
    "mseelnetAIC <- mean((y.test - yelnetAIC)^2)\n",
    "print(paste(\"mse elnet AIC = \",mseelnetAIC))\n",
    "\n",
    "yelnetBIC <- predict(fit5, s=fitelnet$lambda[best_BIC_elnet], newx=x.test)\n",
    "mseelnetBIC <- mean((y.test - yelnetBIC)^2)\n",
    "print(paste(\"mse elnet BIC = \",mseelnetBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error is large for all of the regressions. The most appropriate regression was the Ridge Regression with the lambda determined by the best AIC and the best BIC. It has the smallest mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. signal is variable but there is high correlation among the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(19873)\n",
    "n <- 100    # Number of observations\n",
    "p <- 50     # Number of predictors included in model\n",
    "CovMatrix <- outer(1:p, 1:p, function(x,y) {.7^abs(x-y)}) ##Produce a covariate matrix with x and y as output and a 0.7 correlation\n",
    "\n",
    "x <- mvrnorm(n, rep(0,p), CovMatrix) ##Simulate from a multivariate normal distribution using the covariance matrix defined before\n",
    "y <- 10 * apply(x[, 1:2], 1, sum) + \n",
    "  5 * apply(x[, 3:4], 1, sum) +\n",
    "  apply(x[, 5:14], 1, sum) +\n",
    "  rnorm(n)\n",
    "\n",
    "train_rows <- sample(1:n, .66*n)\n",
    "x.train <- x[train_rows, ]\n",
    "x.test <- x[-train_rows, ]\n",
    "\n",
    "y.train <- y[train_rows]\n",
    "y.test <- y[-train_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitlasso <- glmnet(x.train, y.train, family=\"gaussian\", alpha=1)\n",
    "fitridge <- glmnet(x.train, y.train, family=\"gaussian\", alpha=0)\n",
    "fitelnet <- glmnet(x.train, y.train, family=\"gaussian\", alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 0:10) {\n",
    "    assign(paste(\"fit\", i, sep=\"\"), cv.glmnet(x.train, y.train, type.measure=\"mse\", \n",
    "                                              alpha=i/10,family=\"gaussian\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(3,2))\n",
    "# For plotting options, type '?plot.glmnet' in R console\n",
    "plot(fitlasso, xvar=\"lambda\",label=TRUE)\n",
    "plot(fit10, main=\"LASSO\")\n",
    "\n",
    "plot(fitridge, xvar=\"lambda\")\n",
    "plot(fit0, main=\"Ridge\")\n",
    "\n",
    "plot(fitelnet, xvar=\"lambda\")\n",
    "plot(fit5, main=\"Elastic Net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient values go to zero for the Lasso regression, when the log of lambda is three. Coefficient values go to zero when the log of lambda is above 9 for the Rigid regression. Coefficient values go to zero when the log of lambda is above 3 for the Elastic Net regression. There are four important coefficients displayed in each regression. Of these four variables, two are very important, while the other two are moderately important. The mean squared error plots of the Lasso, Ridge, and Elastic regressions have areas with low variance and areas with high variance. The best ratio of variance and bias occurs approximately at a lambda of log of -2 for the lasso regression. The ridge regression has the best ratio of variance and bias occuring approximately at a lambda of log of 0.5. The elastic net regression has the best ratio of variance and bias occuring at a lambda of log of -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat0 <- predict(fit0, s=fit0$lambda.1se, newx=x.test)\n",
    "mse0 <- mean((y.test - yhat0)^2)\n",
    "yhat5 <- predict(fit5, s=fit5$lambda.1se, newx=x.test)\n",
    "mse5 <- mean((y.test - yhat5)^2)\n",
    "yhat10 <- predict(fit10, s=fit10$lambda.1se, newx=x.test)\n",
    "mse10 <- mean((y.test - yhat10)^2)\n",
    "\n",
    "cat(\"MSE for Ridge Regression\", mse0, \"\\n\")\n",
    "cat(\"MSE for Elastic Net Regression\", mse5, \"\\n\")\n",
    "cat(\"MSE for Lasso Regression\", mse10, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tLL <- fitridge$nulldev - deviance(fitridge) ##Likelihood of the model\n",
    "k <- fitridge$df ##Number of parameters\n",
    "n <- fitridge$nobs ##Sample Size\n",
    "\n",
    "##AIC\n",
    "AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc)\n",
    "cat(\"Best AIC for Rigid: \", m, \"\\n\")\n",
    "best_AIC = match(c(min(AICc)),AICc)\n",
    "print(paste(\"Lambda from AIC Ridge = \",fitridge$lambda[best_AIC]))\n",
    "\n",
    "##BIC\n",
    "BIC<-log(n)*k - tLL \n",
    "m = min(BIC)\n",
    "cat(\"Best BIC for Rigid: \", m, \"\\n\")\n",
    "best_BIC = match(c(min(BIC)),BIC)\n",
    "print(paste(\"Lambda from BIC Ridge = \",fitridge$lambda[best_BIC]))\n",
    "\n",
    "##Lasso\n",
    "##AIC\n",
    "tLL <- fitlasso$nulldev - deviance(fitlasso)\n",
    "k <- fitlasso$df\n",
    "n <- fitlasso$nobs\n",
    "AICc_lasso <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m = min(AICc_lasso)##Best AIC\n",
    "cat(\"Best AIC for Lasso: \", m, \"\\n\")\n",
    "best_AIC_lasso = match(c(min(AICc_lasso)),AICc_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from AIC Lasso = \",fitlasso$lambda[best_AIC_lasso]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_lasso<-log(n)*k - tLL \n",
    "m = min(BIC_lasso)##Best BIC\n",
    "cat(\"Best BIC for Lasso: \", m, \"\\n\")\n",
    "best_BIC_lasso = match(c(min(BIC_lasso)),BIC_lasso)##Which index is this?\n",
    "print(paste(\"Lambda from BIC Lasso= \",fitlasso$lambda[best_BIC_lasso]))\n",
    "\n",
    "##Elastic Net\n",
    "##AIC\n",
    "tLL <- fitelnet$nulldev - deviance(fitelnet)\n",
    "k <- fitelnet$df\n",
    "n <- fitelnet$nobs\n",
    "AICc_elnet <- -tLL+2*k+2*k*(k+1)/(n-k-1)\n",
    "m= min(AICc_elnet)##Best AIC\n",
    "cat(\"Best AIC for Elastic Net: \", m, \"\\n\")\n",
    "best_AIC_elnet = match(c(min(AICc_elnet)),AICc_elnet)##Which index is this?\n",
    "print(paste(\"Lambda AIC enet =\",fitelnet$lambda[best_AIC_elnet]))##Find this lambda\n",
    "\n",
    "##BIC\n",
    "BIC_elnet<-log(n)*k - tLL \n",
    "m= min(BIC_elnet)##Best BIC\n",
    "cat(\"Best BIC for Elastic Net: \", m, \"\\n\")\n",
    "best_BIC_elnet = match(c(min(BIC_elnet)),BIC_elnet)##Which index is this?\n",
    "print(paste(\"Lambda BIC enet= \",fitelnet$lambda[best_BIC_elnet]))\n",
    "\n",
    "#Ridge AIC/BIC\n",
    "yRidgeAIC <- predict(fit0, s=fitridge$lambda[best_AIC], newx=x.test)\n",
    "mseRidgeAIC <- mean((y.test - yRidgeAIC)^2)\n",
    "print(paste(\"mse Ridge AIC = \", mseRidgeAIC))\n",
    "yRidgeBIC <- predict(fit0, s=fitridge$lambda[best_BIC], newx=x.test)\n",
    "mseRidgeBIC <- mean((y.test - yRidgeBIC)^2)\n",
    "print(paste(\"mse Ridge BIC = \", mseRidgeBIC))\n",
    "\n",
    "#Lasso AIC/BIC\n",
    "yLassoAIC <- predict(fit10, s=fitlasso$lambda[best_AIC_lasso], newx=x.test)\n",
    "mseLassoAIC <- mean((y.test - yLassoAIC)^2)\n",
    "print(paste(\"mse Lasso AIC = \", mseLassoAIC)) \n",
    "yLassoBIC <- predict(fit10, s=fitlasso$lambda[best_BIC_lasso], newx=x.test)\n",
    "mseLassoBIC <- mean((y.test - yLassoBIC)^2)\n",
    "print(paste(\"mse Lasso BIC = \", mseLassoBIC)) \n",
    "\n",
    "#Elastic Net AIC/BIC\n",
    "yelnetAIC <- predict(fit5, s=fitelnet$lambda[best_AIC_elnet], newx=x.test)\n",
    "mseelnetAIC <- mean((y.test - yelnetAIC)^2)\n",
    "print(paste(\"mse elnet AIC = \",mseelnetAIC))\n",
    "\n",
    "yelnetBIC <- predict(fit5, s=fitelnet$lambda[best_BIC_elnet], newx=x.test)\n",
    "mseelnetBIC <- mean((y.test - yelnetBIC)^2)\n",
    "print(paste(\"mse elnet BIC = \",mseelnetBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error is small for all of the regressions. The most appropriate regression was the Lasso Regression with the lambda determined by the best AIC and the best BIC. It has the smallest mean squared error. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
